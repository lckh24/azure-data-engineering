{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98dddb1e-69cd-4e7c-aea2-ee4392aece96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class PricePredictionModel:\n",
    "    \"\"\"Class to handle price prediction modeling with preprocessing, training, evaluation, and model saving.\"\"\"\n",
    "    \n",
    "    def __init__(self, data_query):\n",
    "        \"\"\"Initialize with Spark SQL query.\"\"\"\n",
    "        self.data_query = data_query\n",
    "        self.models = {\n",
    "            \"LinearRegression\": LinearRegression(),\n",
    "            \"RandomForest\": RandomForestRegressor(random_state=42),\n",
    "            \"XGBoost\": xgb.XGBRegressor(random_state=42),\n",
    "            \"CatBoost\": cb.CatBoostRegressor(verbose=0, random_state=42)\n",
    "        }\n",
    "        self.param_grids = {\n",
    "            \"LinearRegression\": {\n",
    "                \"model__fit_intercept\": [True, False]\n",
    "            },\n",
    "            \"RandomForest\": {\n",
    "                \"model__n_estimators\": [100, 200],\n",
    "                \"model__max_depth\": [5, 10]\n",
    "            },\n",
    "            \"XGBoost\": {\n",
    "                \"model__n_estimators\": [100, 200],\n",
    "                \"model__max_depth\": [3, 5],\n",
    "                \"model__learning_rate\": [0.01, 0.1]\n",
    "            },\n",
    "            \"CatBoost\": {\n",
    "                \"model__iterations\": [100, 200],\n",
    "                \"model__depth\": [4, 6],\n",
    "                \"model__learning_rate\": [0.01, 0.1]\n",
    "            }\n",
    "        }\n",
    "        self.target = 'MODAL_PRICE'\n",
    "        self.results = []\n",
    "        self.best_model = None\n",
    "        self.best_model_name = None\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        self.preprocessor = None\n",
    "        \n",
    "    def preprocess_data(self, spark):\n",
    "        \"\"\"Preprocess the data from Spark query.\"\"\"\n",
    "        df = spark.sql(self.data_query).toPandas()\n",
    "        df['DATE_OF_PRICING'] = pd.to_datetime(df['DATE_OF_PRICING'])\n",
    "        df['month'] = df['DATE_OF_PRICING'].dt.month\n",
    "        df['dayofweek'] = df['DATE_OF_PRICING'].dt.dayofweek\n",
    "        df['year'] = df['DATE_OF_PRICING'].dt.year\n",
    "        \n",
    "        columns_to_drop = ['DATE_OF_PRICING', 'lakehouse_inserted_date', \n",
    "                           'lakehouse_updated_date', 'ROW_ID', \n",
    "                           'TEMPARATURE_UNIT', 'MARKET_MAX_TEMPARATURE', 'MARKET_POPULATION']\n",
    "        df = df.drop(columns=columns_to_drop, errors='ignore')\n",
    "        df = df.dropna()\n",
    "        \n",
    "        features = df.columns.drop([self.target, 'MAXIMUM_PRICE', 'MINIMUM_PRICE'])\n",
    "        X = df[features]\n",
    "        y = df[self.target]\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            X, y, test_size=0.2, shuffle=False\n",
    "        )\n",
    "        \n",
    "        numerical_cols = X.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "        categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "        \n",
    "        numeric_transformer = Pipeline(steps=[\n",
    "            (\"scaler\", StandardScaler())\n",
    "        ])\n",
    "        \n",
    "        categorical_transformer = Pipeline(steps=[\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown='ignore'))\n",
    "        ])\n",
    "        \n",
    "        self.preprocessor = ColumnTransformer(transformers=[\n",
    "            (\"num\", numeric_transformer, numerical_cols),\n",
    "            (\"cat\", categorical_transformer, categorical_cols)\n",
    "        ])\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def train_and_evaluate(self):\n",
    "        \"\"\"Train models with GridSearchCV and evaluate performance.\"\"\"\n",
    "        self.results = []  # Clear results to avoid duplication\n",
    "        \n",
    "        for name, model in self.models.items():\n",
    "            pipeline = Pipeline(steps=[\n",
    "                (\"preprocessor\", self.preprocessor),\n",
    "                (\"model\", model)\n",
    "            ])\n",
    "            \n",
    "            # Perform GridSearchCV\n",
    "            grid = GridSearchCV(\n",
    "                pipeline,\n",
    "                param_grid=self.param_grids[name],\n",
    "                cv=3,\n",
    "                scoring='neg_root_mean_squared_error',\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            grid.fit(self.X_train, self.y_train)\n",
    "            \n",
    "            # Use the best estimator from GridSearchCV\n",
    "            best_pipeline = grid.best_estimator_\n",
    "            \n",
    "            # Get predictions\n",
    "            train_pred = best_pipeline.predict(self.X_train)\n",
    "            test_pred = best_pipeline.predict(self.X_test)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            train_rmse = mean_squared_error(self.y_train, train_pred, squared=False)\n",
    "            test_rmse = mean_squared_error(self.y_test, test_pred, squared=False)\n",
    "            train_r2 = r2_score(self.y_train, train_pred)\n",
    "            test_r2 = r2_score(self.y_test, test_pred)\n",
    "            \n",
    "            # Check for overfitting/underfitting\n",
    "            fit_status = self._check_fit_status(train_rmse, test_rmse, train_r2, test_r2)\n",
    "            \n",
    "            self.results.append({\n",
    "                \"Model\": name,\n",
    "                \"Train_RMSE\": train_rmse,\n",
    "                \"Test_RMSE\": test_rmse,\n",
    "                \"Train_R2\": train_r2,\n",
    "                \"Test_R2\": test_r2,\n",
    "                \"MAE\": mean_absolute_error(self.y_test, test_pred),\n",
    "                \"Fit_Status\": fit_status,\n",
    "                \"Best_Params\": grid.best_params_\n",
    "            })\n",
    "            \n",
    "            # Update best model if current model has lower Test_RMSE\n",
    "            if self.best_model is None or test_rmse < min(r['Test_RMSE'] for r in self.results[:-1]):\n",
    "                self.best_model = best_pipeline\n",
    "                self.best_model_name = name\n",
    "    \n",
    "    def _check_fit_status(self, train_rmse, test_rmse, train_r2, test_r2):\n",
    "        \"\"\"Check for overfitting and underfitting.\"\"\"\n",
    "        rmse_diff = abs(train_rmse - test_rmse) / train_rmse\n",
    "        r2_diff = abs(train_r2 - test_r2)\n",
    "        \n",
    "        if rmse_diff > 0.2 and train_rmse < test_rmse:\n",
    "            return \"Overfitting\"\n",
    "        elif train_r2 < 0.5 and test_r2 < 0.5:\n",
    "            return \"Underfitting\"\n",
    "        return \"Good Fit\"\n",
    "    \n",
    "    def save_best_model(self, filename=\"best_price_prediction_model.joblib\"):\n",
    "        \"\"\"Save the best model to a file.\"\"\"\n",
    "        if self.best_model is None:\n",
    "            raise ValueError(\"No best model found. Please run train_and_evaluate first.\")\n",
    "        joblib.dump(self.best_model, filename)\n",
    "        print(f\"Best model ({self.best_model_name}) saved to {filename}\")\n",
    "    \n",
    "    def get_results(self):\n",
    "        \"\"\"Return results sorted by Test_RMSE.\"\"\"\n",
    "        results_df = pd.DataFrame(self.results).sort_values(\"Test_RMSE\")\n",
    "        return results_df\n",
    "    \n",
    "    def run(self, spark, save_model=True, model_filename=\"best_price_prediction_model.joblib\"):\n",
    "        \"\"\"Run the complete modeling pipeline.\"\"\"\n",
    "        self.preprocess_data(spark)\n",
    "        self.train_and_evaluate()\n",
    "        if save_model:\n",
    "            self.save_best_model(model_filename)\n",
    "        return self.get_results()\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    from pyspark.sql import SparkSession\n",
    "    \n",
    "    spark = SparkSession.builder.appName(\"PricePrediction\").getOrCreate()\n",
    "    query = \"SELECT * FROM pricing_analytics.gold.datalake_price_prediction_gold\"\n",
    "    model = PricePredictionModel(query)\n",
    "    results = model.run(spark, save_model=True)\n",
    "    print(\"\\nFinal Results:\")\n",
    "    print(results)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Model-Training",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
